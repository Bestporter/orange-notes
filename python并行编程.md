# 第一章 并行计算

计算机系统可以分成以下四类：

- 单处理器，单数据 (SISD)
- 单处理器，多数据 (SIMD)
- 多处理器，单数据 (MISD)
- 多处理器，多数据 (MIMD)

## SISD

单处理器单数据就是“单CPU的机器”，它在单一的数据流上执行指令。在SISD中，指令被顺序地执行。

对于每一个“CPU时钟”，CPU按照下面的顺序执行：

- **Fetch**: CPU 从一片内存区域中（寄存器）获得数据和指令
- **Decode**: CPU对指令进行解码
- **Execute**: 该执行在数据上执行，将结果保存在另一个寄存器中

当Execute阶段完成之后，CPU回到步骤1准备执行下一个时钟循环。

运行在这些计算机上的算法是顺序执行的（连续的），不存在任何并行。只有一个CPU的硬件系统就是SISD的例子。

这种架构（冯·诺依曼体系）的主要元素有以下：

- 中心内存单元：存储指令和数据
- CPU：用于从内存单元获得指令/数据，对指令解码并顺序执行它们
- I/O系统：程序的输入和输出流

## MISD

这种模型中，有n个处理器，每一个都有自己的控制单元，共享同一个内存单元。在每一个CPU时钟中，从内存获得的数据会被所有的处理器同时处理，每一个处理器按照自己的控制单元发送的指令处理。在这种情况下，并行实际上是指令层面的并行，多个指令在相同的数据上操作。能够合理利用这种架构的问题模型比较特殊，例如数据加密等。因此，MISD在现实中并没有很多用武之地，更多的是作为一个抽象模型的存在。

## SIMD

SIMD计算机包括多个独立的处理器，每一个都有自己的局部内存，可以用来存储数据。所有的处理器都在单一指令流下工作；具体说，就是有n个数据流，每个处理器处理一个。所有的处理器同时处理每一步，在不同的数据上执行相同的指令。这是一个数据并行的例子。SIMD架构比MISD架构要实用的多。很多问题都可以用SIMD计算机的架构来解决。这种架构另一个有趣的特性是，这种架构的算法非常好设计，分析和实现。限制是，只有可以被分解成很多个小问题（小问题之间要独立，可以不分先后顺序被相同的指令执行）的问题才可以用这种架构解决。很多超级计算机就是使用这架构设计出来的。例如Connection Machine（1985年的 Thinking Machine)和MPP（NASA-1983）.我们在第六章 GPU Python编程中会接触到高级的现代图形处理器（GPU），这种处理器就是内置了很多个SIMD处理单元，使这种架构在今天应用非常广泛。

## MIMD

在费林分类中，这种计算机是最广泛使用、也是最强大的一个种类。这种架构有n个处理器，n个指令流，n个数据流。每一个处理器都有自己的控制单元和局部内存，让MIMD架构比SIMD架构的计算能力更强。每一个处理器都在独立的控制单元分配的指令流下工作；因此，处理器可以在不同的数据上运行不同的程序，这样可以解决完全不同的子问题甚至是单一的大问题。在MIMD中，架构是通过线程或进程层面的并行来实现的，这也意味着处理器一般是异步工作的。这种类型的计算机通常用来解决那些没有统一结构、无法用SIMD来解决的问题。如今，很多计算机都应用了这中间架构，例如超级计算机，计算机网络等。然而，有一个问题不得不考虑：异步的算法非常难设计、分析和实现。

# 内存管理

​	内存管理是并行架构需要考虑的另一方面，确切来说是获得数据的方式。无论处理单元多快，如果内存提供指令和数据的速度跟不上，系统性能也不会得到提升。**制约内存达到处理器速度级别的响应时间的主要因素是内存存取周期**。所谓**存取周期就是连续启动两次读或写操作所需间隔的最小时间**。处理器的周期通常比内存周期短得多。当处理器传送数据到内存或从内存中获取数据时，内存依旧在一个周期中，其他任何设备（I/O控制器，处理器）都不能使用内存，因为内存必须先对上一个请求作出响应。



​	为了解决 MIMD 架构访问内存的问题，业界提出了两种内存管理系统。第一种就是人们所熟知的**共享内存系统**，共享内存系统有大量的虚拟内存空间，而且各个处理器对内存中的数据和指令拥有平等的访问权限。另外一种类型是**分布式内存模型**，在这种内存模型中，每个处理器都有自己专属的内存，其他处理器都不能访问。共享内存和分布式内存的区别以处理器的角度来说就是内存和虚拟内存体系的不同。每个系统的内存都会分为能独立访问的不同部分。

​	共享内存系统和分布式内存系统的处理单元管理内存访问的方式也不相同。 `load R0,i` 指令意味着将 `i` 内存单元的内容加载进 `R0` 寄存器，但内存管理方式的不同，处理器的处理方式也不尽相同。**在共享内存的系统中， `i` 代表的是内存的全局地址，对系统中的所有处理器来说都指向同一块内存空间**。如果两个处理器想同时执行该内存中的指令，**它们会向 `R0` 寄存器载入相同的内容**。**在分布式内存系统中， `i` 是局部地址。如果两个处理器同时执行向 `R0` 载入内容的语句，执行结束之后，不同处理器 `R0` 寄存器中的值一般情况下是不一样的，因为每个处理器对应的内存单元中的 `i` 代表的全局地址不一样。**对于程序员来说，**必须准确的区分共享内存和分布式内存**，因为在并行编程中需要考量**内存管理方式来决定进程或线程间通讯的方式。**对于共享内存系统来说，**共享内存能够在内存中构建数据结构并在子进程间通过引用直接访问该数据结构。而对于分布式内存系统来说，必须在每个局部内存保存共享数据的副本。**一个处理器会向其他处理器发送含有共享数据的消息从而创建数据副本。这使得分布式内存管理有一个显而易见的缺点，那就是，如果要发送的消息太大，发送过程会耗费相对较长的时间。

## 共享内存

下图展示了共享内存多处理器系统的架构，这里只展示了各部件之间简单的物理连接。总线结构允许任意数量的设备共享一个通道。总线协议最初设计是让单处理器，一个或多个磁盘和磁带控制器通过共享内存进行通讯。可以注意到**处理器拥有各自的Cache，Cache中保存着局部内存中有可能被处理器使用的指令或数据。**可以想象一下，当一个处理器修改了内存中的数据，同时另外一个处理器正在使用这个数据时，就会出现问题。已修改的值会从处理器的Cache传递到共享内存中，接着，新值会传递到其他处理器的Cache中，**其它处理器就不可以使用旧值进行计算。**这就是人们所熟知的**Cache一致性问题**，是内存一致性问题的一种特殊情况，要解决这个问题需要硬件能像多进程编程一样实现处理并发问题 和同步控制 。

### 共享内存系统的主要特性

- 内存对于所有处理器来说是一样的，例如，**所有处理器所对应的相同数据结构都存在于相同的逻辑地址，也就是说可以从相同的内存单元中获得该数据结构。**
- 通过控制处理器对共享内存的访问权限可以达到同步控制的效果。实际上，**每次只有一个处理器拥有对内存资源的访问权限**。
- 当一个任务正在访问共享内存的时候，其它所有任务都**不能改变内存单元的内容。**
- 共享内存很快，**两个任务通讯的时间和读取单个内存单元的时间相等**（取决于内存的访问速度）

### 在共享内存系统中访问内存的方式

- 均匀内存访问 (Uniform memory access (UMA) )：这类系统的基本特征是无论**对于处理器来说访问任意的内存区域速度是相同的**。因此，这些系统也成为**对称式多处理器** (symmetric multiprocessor (SMP)) 系统。这类系统实现起来相对简单，但是可扩展性较差，程序员需要通过插入适当的控制、信号量、锁等机制来管理同步，进而在程序中管理资源。
- 非均匀内存访问 (Non-uniform memory access (NUMA))：这类架构将**内存分为高速访问区域和低速访问区域**。**高速访问区域是分配给各个处理器的区域，是用于数据交换的公用区域。**这类系统也称为**分布式共享内存系统** (Distributed Shared Memory Systems (DSM)) ，这类系统的扩展性很好，但开发难度较高。
- 无远程内存访问 (No remote memory access (NORMA))：对于处理器来说内存在物理上是分布式存在的。每个处理器只能访问其局部私有内存。处理器之间通过消息传递协议进行通讯。
- 仅Cache可访问 (Cache only memory access (COMA))：这类系统中仅有Cache内存。分析 NUMA 架构时，需要注意的是这类系统会把数据的副本保存在Cache中供处理器使用，并且在主存中也保留着重复的数据。COMA 架构可以移除重复的主存数据，而只保留Cache内存。对于处理器来说内存在物理上是分布式存在的。每个处理器只能访问其局部私有内存。处理器之间通过消息传递协议进行通讯。

